{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import shap\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim.lr_scheduler import LambdaLR, LinearLR, SequentialLR\n",
    "from functools import partial\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "from codes.models.metrics import calculate_roc_auc\n",
    "from codes.models.data_form.DataForm import DataTransfo_1SNP, PatientList, Patient\n",
    "from codes.models.Transformers.dic_model_versions import DIC_MODEL_VERSIONS\n",
    "from codes.tests.TestsClass import TestSet, TrainTransformerModel, TrainModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model =  TrainModel.load_instance_test(242)\n",
    "model = train_model.model\n",
    "model.device = 'cpu'\n",
    "patient_list = train_model.patient_list\n",
    "data = train_model.dataT\n",
    "nb_max_distinct_disease = len(patient_list[0].diseases_sentence)\n",
    "nb_max_distinct_diseases_tot = patient_list.get_nb_distinct_diseases_tot()\n",
    "\n",
    "frequencies = np.zeros(nb_max_distinct_diseases_tot)\n",
    "for patient in patient_list:\n",
    "    frequencies[patient.diseases_sentence] +=1 \n",
    "frequencies /= len(patient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train, indices_test = train_model.dataT.indices_train, train_model.dataT.indices_test\n",
    "train_model.patient_list_transformer_train, train_model.patient_list_transformer_test = train_model.patient_list.get_transformer_data(indices_train.astype(int), indices_test.astype(int))\n",
    "#creation of torch Datasets:\n",
    "dataloader_train = DataLoader(train_model.patient_list_transformer_train, batch_size=train_model.batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(train_model.patient_list_transformer_test, batch_size=train_model.batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Calibration plots ##############################################################\n",
    "f1, accuracy, auc_score, loss, proba_avg_zero, proba_avg_one, predicted_probas_list, true_labels_list = model.evaluate(dataloader_train)\n",
    "predicted_probs_ones = np.array(predicted_probas_list)[:, 1]\n",
    "true_labels = np.array(true_labels_list)\n",
    "plt.hist(predicted_probs_ones, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(true_labels_list, predicted_probs_ones, n_bins=80)\n",
    "auc = calculate_roc_auc(true_labels_list, predicted_probs_ones)\n",
    "# Tracer le graphique de calibration\n",
    "plt.plot(prob_pred, prob_true, marker='o', linestyle='--', label='Calibration Plot')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plot')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse of the number of diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_diseases, list_counts, list_labels = zip(*train_model.patient_list_transformer_train)\n",
    "list_diseases = np.array(list_diseases)\n",
    "list_counts = np.array(list_counts)\n",
    "list_labels = np.array(list_labels)\n",
    "\n",
    "nb_diseases = np.sum(list_diseases !=0, axis=1)\n",
    "predicted_labels = (predicted_probs_ones > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nb_disease in np.unique(nb_diseases):\n",
    "    indices = nb_diseases == nb_disease\n",
    "    true = true_labels[indices]\n",
    "    pred = predicted_labels[indices]\n",
    "    acc.append(np.sum(true==pred)/len(true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse of the well predicted patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_diseases, list_counts, list_labels = zip(*train_model.patient_list_transformer_train)\n",
    "list_diseases = np.array(list_diseases)\n",
    "list_counts = np.array(list_counts)\n",
    "list_labels = np.array(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_predicted_low = predicted_probs_ones<0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_selected = list_diseases[indices_predicted_low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(indices_predicted_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_selected = np.zeros(nb_max_distinct_diseases_tot)\n",
    "for disease_sentence in patients_selected:\n",
    "    frequencies_selected[disease_sentence] += 1\n",
    "frequencies_selected /= np.sum(indices_predicted_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_ratio = np.abs(frequencies - frequencies_selected)/frequencies\n",
    "#diff_frequencies =np.max(np.concatenate([frequencies_ratio,  frequencies_ratio**-1], axis=0).reshape(2, len(frequencies_ratio)), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff_frequencies = diff_frequencies[diff_frequencies!=np.inf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(frequencies_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_ratio[15], frequencies[15], frequencies_selected[15]*2330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frequencies_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(patient_list.patients_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_selected = np.array(patient_list.patients_list)[indices_predicted_low]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentence, batch_counts, batch_labels = next(iter(dataloader_test))\n",
    "batch_sentence = batch_sentence\n",
    "batch_counts = batch_counts\n",
    "input_data = [batch_sentence.to(torch.float), batch_counts.to(torch.float)]\n",
    "shap_input = [batch_sentence.to(torch.float)[0].view(1, 122), batch_counts.to(torch.float)[0].view(1, 122)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.shap=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(model, input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(shap_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering patients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases_batch, counts_batch, labels_batch = next(iter(dataloader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, probas, x_out = model.forward_decomposed(diseases_batch, counts_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = 9\n",
    "torch.sum(model.padding_mask[indice][0]==1), torch.sum(diseases_batch[indice]!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_probas_raw = model.list_attention_layers\n",
    "attention_probas_list = []\n",
    "for attention_probas in attention_probas_raw:\n",
    "    attention_probas_list.append(attention_probas.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_sentence = 1\n",
    "indice_layer = 0\n",
    "indice_head = 1\n",
    "\n",
    "attention_probas = attention_probas_list[indice_layer][indice_sentence][indice_head]\n",
    "mask = model.padding_mask.detach().numpy()[indice_sentence].astype(bool)\n",
    "n_real = np.sum(mask[0])\n",
    "\n",
    "attention_probas_masked = attention_probas[mask].reshape(n_real, n_real)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(attention_probas_masked, cmap=\"YlGnBu\", annot=False, fmt=\".2f\", cbar=True)\n",
    "\n",
    "# Ajoutez des étiquettes pour les axes\n",
    "plt.xlabel(\"Token\")\n",
    "plt.ylabel(\"Token\")\n",
    "plt.title(\"Self-Attention Matrix\")\n",
    "\n",
    "# Affichez le plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## definition of the attention score:\n",
    "nb_distinct_diseases_tot = patient_list.get_nb_distinct_diseases_tot()\n",
    "frequencies = np.zeros(nb_distinct_diseases_tot)\n",
    "attention_score_diseases = np.zeros(nb_distinct_diseases_tot)\n",
    "for batch_sentence, batch_counts, batch_labels in dataloader_train:\n",
    "    logits, probas, x_out = model.forward_decomposed(diseases_batch, counts_batch)\n",
    "    attention_probas_raw = model.list_attention_layers\n",
    "    attention_probas_list = []\n",
    "    for attention_probas in attention_probas_raw:\n",
    "        attention_probas_list.append(attention_probas.detach().numpy())\n",
    "\n",
    "    for indice_layer in range(train_model.n_layer):\n",
    "        for indice_head in range(train_model.n_head):\n",
    "            for indice_sentence in range(len(batch_sentence)):\n",
    "                sentence = diseases_batch[indice_sentence]\n",
    "                attention_probas = attention_probas_list[indice_layer][indice_sentence][indice_head]\n",
    "                mask = model.padding_mask.detach().numpy()[indice_sentence].astype(bool)\n",
    "                n_real = np.sum(mask[0])\n",
    "                sentence = sentence[:n_real]\n",
    "                frequencies[sentence] +=1\n",
    "                attention_probas_masked = attention_probas[mask].reshape(n_real, n_real)\n",
    "\n",
    "\n",
    "                attention_score_diseases[sentence] += attention_probas_masked.sum(axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_freq = attention_score_diseases / frequencies\n",
    "attention_score_freq[np.isnan(attention_score_freq)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(attention_score_freq, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(attention_score_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_dicts = train_model.dataT.dicts['id']\n",
    "pheno_dicts_reverse = {value:key for key, value in pheno_dicts.items()}\n",
    "name_dicts = train_model.dataT.dicts['name']\n",
    "name_dicts_reverse = {value:key for key, value in name_dicts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_dicts_reverse[1373], name_dicts[pheno_dicts_reverse[1373]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_freq = attention_score_diseases / frequencies\n",
    "attention_score_freq[np.isnan(attention_score_freq)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(attention_score_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(attention_score_freq, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_diseases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_weights = probas[:, :n_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_weights[12].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(probas_weights.detach().cpu(), cmap=\"YlGnBu\", annot=False, fmt=\".2f\", cbar=True)\n",
    "\n",
    "# Ajoutez des étiquettes pour les axes\n",
    "plt.xlabel(\"Token\")\n",
    "plt.ylabel(\"Token\")\n",
    "plt.title(\"Self-Attention Matrix\")\n",
    "\n",
    "# Affichez le plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, probas, x_out = model.forward_decomposed(diseases_batch, counts_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_probas = model.list_attention_layers[1][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_probas.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.list_attention_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.dataT.indices_test, train_model.dataT.indices_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_model.dataT.indices_test) + len( train_model.dataT.indices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, accuracy, auc_score, loss, proba_avg_zero, proba_avg_one, predicted_probas_list, true_labels_list = model.evaluate(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs_ones = np.array(predicted_probas_list)[:, 1]\n",
    "true_labels = np.array(true_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_probs_ones)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predicted_probs_ones, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(true_labels_list, predicted_probs_ones, n_bins=80)\n",
    "auc = calculate_roc_auc(true_labels_list, predicted_probs_ones)\n",
    "# Tracer le graphique de calibration\n",
    "plt.plot(prob_pred, prob_true, marker='o', linestyle='--', label='Calibration Plot')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plot')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, edges = np.histogram(predicted_probs_ones, bins=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_auc = []\n",
    "for i in range(len(edges[:-1])):\n",
    "    indices_bin = np.intersect1d(np.where(predicted_probs_ones>=edges[i]) , np.where(predicted_probs_ones<edges[i+1]) )\n",
    "    bin_probas = predicted_probs_ones[indices_bin]\n",
    "    bin_labels = true_labels[indices_bin]\n",
    "    bin_auc = calculate_roc_auc(bin_labels, bin_probas)\n",
    "    list_auc.append(bin_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "indices_bin = np.intersect1d(np.where(predicted_probs_ones>=edges[i]) , np.where(predicted_probs_ones<edges[i+1]) )\n",
    "bin_probas = predicted_probs_ones[indices_bin]\n",
    "bin_labels = true_labels[indices_bin]\n",
    "bin_auc = calculate_roc_auc(bin_labels, bin_probas)\n",
    "list_auc.append(bin_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = (bin_probas>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels, bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = np.zeros(patient_list.get_nb_distinct_diseases_tot())\n",
    "counts_ok = 0\n",
    "counts = np.zeros(patient_list.get_nb_distinct_diseases_tot())\n",
    "for k, patient in enumerate(patient_list):\n",
    "    if k in train_model.dataT.indices_test:\n",
    "        diseases_sentence = torch.tensor(patient.diseases_sentence).view(1, nb_max_distinct_disease)\n",
    "        counts_sentence = torch.tensor(patient.counts_sentence).view(1, nb_max_distinct_disease)\n",
    "        label_pred_patient = model.predict(diseases_sentence, counts_sentence)\n",
    "        if label_pred_patient[0]==patient.SNP_label:\n",
    "            counts_ok += 1\n",
    "            res[patient.diseases_sentence] = res[patient.diseases_sentence] + 1\n",
    "        counts[patient.diseases_sentence] = counts[patient.diseases_sentence] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, probas, attention_probas, attention_weights = model.forward_decomposed(diseases_sentence, counts_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_pheno(data, labels, pheno_nb):\n",
    "    labels_ac = labels[data[:,pheno_nb]==1]\n",
    "    labels_deac = labels[data[:,pheno_nb]==0]\n",
    "    proba_mut_ac = np.sum(labels_ac==1)/len(labels_ac)\n",
    "    proba_mut_deac = np.sum(labels_deac==1)/len(labels_deac)\n",
    "    ratio  = proba_mut_ac / proba_mut_deac\n",
    "    return ratio\n",
    "def get_pred_naive(data, labels, pheno_nb):\n",
    "    labels_ac = labels[data[:,pheno_nb]==1]\n",
    "    nb_ones_ac = np.sum(labels_ac==1)\n",
    "    nb_zeros_ac = np.sum(labels_ac==0)\n",
    "    return (1 if nb_ones_ac > nb_zeros_ac else 0)\n",
    "get_risk_pheno = partial(get_risk_pheno, data, labels)\n",
    "get_pred_naive = partial(get_pred_naive, data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_ratios = list(map(get_risk_pheno, phenos))\n",
    "labels_pred_naive = list(map(get_pred_naive, phenos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (np.array(probas) < 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - np.sum((preds-labels_pred_naive)**2)/1717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### correlations with number zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_res = []\n",
    "nb_zeros_res = []\n",
    "for patient in patient_list:\n",
    "    diseases_sentence = torch.tensor(patient.diseases_sentence).view(1, nb_max_distinct_disease)\n",
    "    counts_sentence = torch.tensor(patient.counts_sentence).view(1, nb_max_distinct_disease)\n",
    "    label_pred_patient = model.predict(diseases_sentence, counts_sentence)\n",
    "    nb_zeros = torch.sum(diseases_sentence==0)\n",
    "    labels_res.append(label_pred_patient[0].item())\n",
    "    nb_zeros_res.append(nb_zeros.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_zeros_res = np.array(nb_zeros_res)\n",
    "labels_res = np.array(labels_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_zeros_res, labels_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.unique(nb_zeros_res)\n",
    "labels = [np.mean(labels_res[nb_zeros_res == nb_zero]) for nb_zero in zeros ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(zeros, labels, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Calibration plot ################\n",
    "for patient in patient_list:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for patient in patient_list:\n",
    "    if patient.diseases_sentence[0]==0:\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file ='/gpfs/commons/groups/gursoy_lab/mstoll/codes/Data_Files/Pheno/Paul/ukbb_omop_rolled_up_depth_4_closest_ancestor.csv'\n",
    "df_paul = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid_list = df_paul.eid\n",
    "eid = eid_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_paul.groupby('eid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = grouped.get_group(eid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_codes = list(df['concept_id'].values)\n",
    "occurrences = list(df['condition_occurrence_count'].values)\n",
    "\n",
    "disease_sentence = [code for code in unique_codes]\n",
    "counts_sentence = [count for count in occurrences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phewas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
