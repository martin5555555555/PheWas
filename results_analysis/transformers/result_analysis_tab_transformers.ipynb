{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim.lr_scheduler import LambdaLR, LinearLR, SequentialLR\n",
    "from functools import partial\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "from codes.models.metrics import calculate_roc_auc\n",
    "from codes.models.data_form.DataForm import DataTransfo_1SNP, PatientList, Patient\n",
    "from codes.models.Transformers.dic_model_versions import DIC_MODEL_VERSIONS\n",
    "from codes.tests.TestsClass import TestSet, TrainTabTransformerModel, TrainModel\n",
    "import matplotlib.pyplot as plt\n",
    "from codes.models.data_form.DataSets import TabDictDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model =  TrainModel.load_instance_test(140)\n",
    "model = train_model.model\n",
    "model.device = 'cpu'\n",
    "data = train_model.dataT\n",
    "dic_data = train_model.dic_data\n",
    "dic_data_train = train_model.dic_data_train\n",
    "\n",
    "dic_data_test = train_model.dic_data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TabDictDataset(dic_data_train)\n",
    "dataset_test = TabDictDataset(dic_data_test)\n",
    "\n",
    "dataloader_train =  DataLoader(dataset_train, batch_size = train_model.batch_size, shuffle=True)\n",
    "dataloader_test =  DataLoader(dataset_test, batch_size = train_model.batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward_decomposed(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phewas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
