{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorboard\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "from rich.progress import Progress\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim.lr_scheduler import LambdaLR, LinearLR, SequentialLR\n",
    "from functools import partial\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "from codes.models.data_form.DataForm import DataTransfo_1SNP\n",
    "from codes.models.Transformers.Embedding import EmbeddingPheno\n",
    "from codes.models.Transformers.dic_model_versions import DIC_MODEL_VERSIONS\n",
    "from codes.models.utils import clear_last_line, print_file, number_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### framework constants:\n",
    "model_type = 'transformer'\n",
    "model_version = 'transformer_V1'\n",
    "test_name = 'test_train_transfo_V1'\n",
    "pheno_method = 'Abby' # Paul, Abby\n",
    "tryout = True # True if we are ding a tryout, False otherwise \n",
    "### data constants:\n",
    "CHR = 1\n",
    "SNP = 'rs673604'\n",
    "rollup_depth = 4\n",
    "Classes_nb = 2 #nb of classes related to an SNP (here 0 or 1)\n",
    "vocab_size = None # to be defined with data\n",
    "padding_token = 0\n",
    "prop_train_test = 0.8\n",
    "load_data = True\n",
    "save_data = False\n",
    "remove_none = True\n",
    "compute_features = True\n",
    "padding = True\n",
    "### data format\n",
    "batch_size = 20\n",
    "data_share = 1/100\n",
    "\n",
    "##### model constants\n",
    "embedding_method = None #None, Paul, Abby\n",
    "freeze_embedding = False\n",
    "Embedding_size = 20 # Size of embedding.\n",
    "n_head = 4 # number of SA heads\n",
    "n_layer = 1 # number of blocks in parallel\n",
    "Head_size = 20  # size of the \"single Attention head\", which is the sum of the size of all multi Attention heads\n",
    "eval_epochs_interval = 1 # number of epoch between each evaluation print of the model (no impact on results)\n",
    "eval_batch_interval = 10\n",
    "p_dropout = 0 # proba of dropouts in the model\n",
    "masking_padding = False # do we include padding masking or not\n",
    "seuil_diseases = 50\n",
    "loss_version = 'focal_loss'\n",
    "equalize_label = False\n",
    "gamma = 2\n",
    "##### training constants\n",
    "total_epochs = 10 # number of epochs\n",
    "learning_rate_max = 0.01 # maximum learning rate (at the end of the warmup phase)\n",
    "learning_rate_ini = 0.001 # initial learning rate\n",
    "learning_rate_final = 0.001 \n",
    "warm_up_frac = 0.20 # fraction of the size of the warmup stage with regards to the total number of epochs.\n",
    "start_factor_lr = learning_rate_ini / learning_rate_max\n",
    "end_factor_lr = learning_rate_final / learning_rate_max\n",
    "warm_up_size = int(total_epochs*warm_up_frac)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def lr_lambda(current_epoch, warm_up_size=warm_up_size): ## function that defines the evolution of the learning rate.\n",
    "    warm_up_size = int(total_epochs*warm_up_frac)\n",
    "    if current_epoch < warm_up_size:\n",
    "        return learning_rate_ini + current_epoch*(learning_rate_max - learning_rate_ini) / warm_up_size\n",
    "    else:\n",
    "        return learning_rate_max / (current_epoch - warm_up_size + 1)\n",
    "lr_lambda = partial(lr_lambda, warm_up_size=warm_up_size) \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### links towards directories\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/codes/'\n",
    "\n",
    "#check test name\n",
    "model_dir = path + f'logs/SNPS/{str(CHR)}/{SNP}/{model_type}/{model_version}/{pheno_method}'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "#check number tests\n",
    "number_test = number_tests(model_dir)\n",
    "test_name_with_infos = str(number_test) + '_' + test_name + 'tryout'*tryout\n",
    "test_dir = f'{model_dir}/{test_name_with_infos}/'\n",
    "log_model_dir = f'{test_dir}/model/'\n",
    "log_data_dir = f'{test_dir}/data/'\n",
    "log_info_dir = f'{test_dir}/infos/tensorboard/'\n",
    "log_slurm_outputs_dir = f'{test_dir}/Slurm/Outputs/'\n",
    "\n",
    "os.makedirs(log_model_dir)\n",
    "os.makedirs(log_data_dir)\n",
    "os.makedirs(log_info_dir)\n",
    "os.makedirs(log_slurm_outputs_dir)\n",
    "\n",
    "log_model_path_torch = f'{test_dir}/model/{test_name}.pth'\n",
    "log_model_path_pickle = f'{test_dir}/model/{test_name}.pkl'\n",
    "log_data_path_pickle = f'{test_dir}/data/{test_name}.pkl'\n",
    "\n",
    "\n",
    "log_info_path = f'{test_dir}/infos/tensorboard/{test_name}'\n",
    "log_slurm_outputs_path = f'{test_dir}/Slurm/Outputs/{test_name}.pth'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = DataTransfo_1SNP(SNP=SNP,\n",
    "                         CHR=CHR,\n",
    "                         method=pheno_method,\n",
    "                         padding=padding,  \n",
    "                         pad_token=padding_token, \n",
    "                         load_data=load_data, \n",
    "                         save_data=save_data, \n",
    "                         compute_features=compute_features,\n",
    "                         data_share=data_share,\n",
    "                         prop_train_test=prop_train_test,\n",
    "                         remove_none=remove_none,\n",
    "                         rollup_depth=rollup_depth, \n",
    "                         equalize_label=equalize_label, \n",
    "                         seuil_diseases=seuil_diseases\n",
    "                         )\n",
    "patient_list = dataT.get_patientlist()\n",
    "patient_list.padd_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train, indices_test = dataT.get_indices_train_test(patient_list=patient_list,prop_train_test=prop_train_test)\n",
    "patient_list_transformer_train, patient_list_transformer_test = patient_list.get_transformer_data(indices_train.astype(int), indices_test.astype(int))\n",
    "#creation of torch Datasets:\n",
    "dataloader_train = DataLoader(patient_list_transformer_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(patient_list_transformer_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patient_list.nb_distinct_diseases_tot==None:\n",
    "    vocab_size = patient_list.get_nb_distinct_diseases_tot()\n",
    "if patient_list.nb_max_counts_same_disease==None:\n",
    "    max_count_same_disease = patient_list.get_max_count_same_disease()\n",
    "max_count_same_disease = patient_list.nb_max_counts_same_disease\n",
    "vocab_size = patient_list.nb_distinct_diseases_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n vocab_size : {vocab_size}, max_count : {max_count_same_disease}\\n', \n",
    "      f'length_patient = {patient_list.get_nb_max_distinct_diseases_patient()}\\n',\n",
    "      f'sparcity = {patient_list.sparsity}\\n',\n",
    "      f'nombres patients  = {len(patient_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding  = EmbeddingPheno(method=embedding_method, \n",
    "                            vocab_size=vocab_size, \n",
    "                            max_count_same_disease=max_count_same_disease, \n",
    "                            Embedding_size=Embedding_size, \n",
    "                            rollup_depth=rollup_depth, \n",
    "                            freeze_embed=freeze_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creation of the model\n",
    "ClassModel = DIC_MODEL_VERSIONS[model_version]\n",
    "model = ClassModel(pheno_method = pheno_method,\n",
    "                             Embedding = Embedding,\n",
    "                             Head_size=Head_size,\n",
    "                             Classes_nb=Classes_nb,\n",
    "                             n_head=n_head,\n",
    "                             n_layer=n_layer,\n",
    "                             mask_padding=masking_padding, \n",
    "                             padding_token=0, \n",
    "                             p_dropout=p_dropout, \n",
    "                             loss_version = loss_version, \n",
    "                             gamma = gamma)\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, accuracy, report, auc_score, val_loss, proba_avg_zero, proba_avg_one, predicted_probas_list, true_labels_list = model.evaluate(dataloader_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate_max)\n",
    "lr_scheduler_warm_up = LinearLR(optimizer, start_factor=start_factor_lr , end_factor=1, total_iters=warm_up_size, verbose=False) # to schedule a modification in the learning rate\n",
    "lr_scheduler_final = LinearLR(optimizer, start_factor=1, total_iters=total_epochs-warm_up_size, end_factor=end_factor_lr)\n",
    "lr_scheduler = SequentialLR(optimizer, schedulers=[lr_scheduler_warm_up, lr_scheduler_final], milestones=[warm_up_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open tensor board writer\n",
    "output_file = log_slurm_outputs_path\n",
    "with open(output_file, 'w') as file:\n",
    "    file.truncate()\n",
    "    file.close()\n",
    "writer = SummaryWriter(log_info_path)\n",
    "# Training Loop\n",
    "start_time_training = time.time()\n",
    "print_file(output_file, f'Beginning of the program for {total_epochs} epochs', new_line=True)\n",
    "# Training Loop\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    start_time_epoch = time.time()\n",
    "    total_loss = 0.0  \n",
    "    print_file(output_file, 'will be deleted', new_line=True)\n",
    "    #with tqdm(total=len(dataloader_train), position=0, leave=True) as pbar:\n",
    "    for k, (batch_sentences, batch_counts, batch_labels) in enumerate(dataloader_train):\n",
    "        \n",
    "        batch_sentences = batch_sentences.to(device)\n",
    "        batch_counts = batch_counts.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        # evaluate the loss\n",
    "        logits, loss = model(batch_sentences, batch_counts, batch_labels)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "    \n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if k %eval_batch_interval == 0:\n",
    "            clear_last_line(output_file)\n",
    "            print_file(output_file, f'Progress in batch = {round(k / len(dataloader_train)*100, 2)} %, time batch : {time.time() - start_time_epoch}', new_line=False)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    writer.add_scalar('Training loss', total_loss/len(dataloader_train), epoch)\n",
    "\n",
    "    if epoch % eval_epochs_interval == 0:\n",
    "        print_file(output_file, f\"Epoch {epoch} finished: {int(time.time() - start_time_epoch)} seconds\", new_line=True)\n",
    "        print_file(output_file, f\"    Training loss : {(total_loss/len(dataloader_train)):.4f}\", new_line = True)\n",
    "        f1, accuracy, report, auc_score, val_loss, proba_avg_zero, proba_avg_one, predicted_probas_list, true_labels_list = model.evaluate(dataloader_test)\n",
    "        print_file(output_file, \" Evaluation on validation\", new_line=True)\n",
    "        print_file(output_file, f\"        Validation loss : {val_loss:.4f}\", new_line=True)\n",
    "        writer.add_scalar('Validation loss', val_loss, epoch)\n",
    "        writer.add_scalar('Validation AUC', auc_score, epoch)\n",
    "        writer.add_scalar('Validation f1-score', f1, epoch)\n",
    "        writer.add_scalar('Validation accuracy', accuracy, epoch)\n",
    "        writer.add_scalar('Average Proba 0', proba_avg_zero, epoch)\n",
    "        writer.add_scalar('Average Proba 1', proba_avg_one, epoch)\n",
    "\n",
    "        print_file(output_file, f\"learning rate : {optimizer.param_groups[0]['lr']}\", new_line=True)\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), log_model_path_torch)\n",
    "print('Model saved to %s' % log_model_path_torch)\n",
    "# Print time\n",
    "print(f\"Training finished: {int(time.time() - start_time_training)} seconds\")\n",
    "start_time = time.time()\n",
    "\n",
    "with open(log_model_path_pickle, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "print('Model saved to %s' % log_model_path_pickle)\n",
    "\n",
    "dic_data = {\n",
    "    'patient_list':patient_list,\n",
    "    'data' : dataT\n",
    "}\n",
    "with open(log_data_path_pickle, 'wb') as file:\n",
    "    pickle.dump(dic_data, file)\n",
    "print('Data saved to %s' % log_data_path_pickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.mean(np.array(predicted_probas_list)[:,1][np.array(true_labels_list)==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randint(4, (2,), dtype=float)\n",
    "probas = F.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(logits, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = probas[0]\n",
    "p2 = probas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Oter implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open tensor board writer\n",
    "writer = SummaryWriter(log_path)\n",
    "# Training Loop\n",
    "start_time_training = time.time()\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    start_time_epoch = time.time()\n",
    "    total_loss = 0.0  \n",
    "\n",
    "    for (batch_sentences, batch_counts, batch_labels) in tqdm(dataloader_train,desc=f\"Processing batch\", unit=\"group\"):\n",
    "        batch_sentences = batch_sentences.to(device)\n",
    "        batch_counts = batch_counts.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        # evaluate the loss\n",
    "        logits, loss = model(batch_sentences, batch_counts, batch_labels)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "    \n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    writer.add_scalar('Training loss', total_loss/len(dataloader_train), epoch)\n",
    "\n",
    "    if epoch % eval_interval == 0:\n",
    "        print(f\"Epoch {epoch} finished: {int(time.time() - start_time_epoch)} seconds\")\n",
    "        print(f\"    Training loss : {(total_loss/len(dataloader_train)):.4f}\")\n",
    "        f1, accuracy, report, auc_score, val_loss = model.evaluate(dataloader_test)\n",
    "        print(\" Evaluation on validation\")\n",
    "        print(f\"        Validation loss : {val_loss:.4f}\")\n",
    "        writer.add_scalar('Validation loss', val_loss, epoch)\n",
    "        writer.add_scalar('Validation AUC', auc_score, epoch)\n",
    "        writer.add_scalar('Validation f1-score', f1, epoch)\n",
    "        writer.add_scalar('Validation accuracy', accuracy, epoch)\n",
    "        \n",
    "        print(f\"learning rate : {optimizer.param_groups[0]['lr']}\")\n",
    "    \n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('Model saved to %s' % model_path)\n",
    "# Print time\n",
    "print(f\"Training finished: {int(time.time() - start_time_training)} seconds\")\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    start_time_epoch = time.time()\n",
    "    total_loss = 0.0  \n",
    "    with tqdm(total=100, desc=\"Progress\") as pbar:\n",
    "\n",
    "        for batch_sentences, batch_counts, batch_labels in dataloader_train:\n",
    "\n",
    "            batch_sentences = batch_sentences.to(device)\n",
    "            batch_counts = batch_counts.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # evaluate the loss\n",
    "            logits, loss = model(batch_sentences, batch_counts, batch_labels)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "        \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        writer.add_scalar('Training loss', total_loss/len(dataloader_train), epoch)\n",
    "\n",
    "        if epoch % eval_interval == 0:\n",
    "            print(f\"Epoch {epoch} finished: {int(time.time() - start_time_epoch)} seconds\")\n",
    "            print(f\"    Training loss : {(total_loss/len(dataloader_train)):.4f}\")\n",
    "            f1, accuracy, report, auc_score, val_loss = model.evaluate(dataloader_test)\n",
    "            print(\" Evaluation on validation\")\n",
    "            print(f\"        Validation loss : {val_loss:.4f}\")\n",
    "            writer.add_scalar('Validation loss', val_loss, epoch)\n",
    "            writer.add_scalar('Validation AUC', auc_score, epoch)\n",
    "            writer.add_scalar('Validation f1-score', f1, epoch)\n",
    "            writer.add_scalar('Validation accuracy', accuracy, epoch)\n",
    "            \n",
    "            print(f\"learning rate : {optimizer.param_groups[0]['lr']}\")\n",
    "        \n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('Model saved to %s' % model_path)\n",
    "# Print time\n",
    "print(f\"Training finished: {int(time.time() - start_time_training)} seconds\")\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "with Progress() as progress:\n",
    "    task1 = progress.add_task(\"Training model\", total=total_epochs)\n",
    "    task2 = progress.add_task(\"epoch\", total=len(dataloader_train))\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        start_time_epoch = time.time()\n",
    "        total_loss = 0.0  \n",
    "\n",
    "        for batch_sentences, batch_counts, batch_labels in dataloader_train:\n",
    "\n",
    "            batch_sentences = batch_sentences.to(device)\n",
    "            batch_counts = batch_counts.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # evaluate the loss\n",
    "            logits, loss = model(batch_sentences, batch_counts, batch_labels)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "        \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            progress.update(task2, advance=1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        writer.add_scalar('Training loss', total_loss/len(dataloader_train), epoch)\n",
    "\n",
    "        if epoch % eval_interval == 0:\n",
    "            print(f\"Epoch {epoch} finished: {int(time.time() - start_time_epoch)} seconds\")\n",
    "            print(f\"    Training loss : {(total_loss/len(dataloader_train)):.4f}\")\n",
    "            f1, accuracy, report, auc_score, val_loss = model.evaluate(dataloader_test)\n",
    "            print(\" Evaluation on validation\")\n",
    "            print(f\"        Validation loss : {val_loss:.4f}\")\n",
    "            writer.add_scalar('Validation loss', val_loss, epoch)\n",
    "            writer.add_scalar('Validation AUC', auc_score, epoch)\n",
    "            writer.add_scalar('Validation f1-score', f1, epoch)\n",
    "            writer.add_scalar('Validation accuracy', accuracy, epoch)\n",
    "            \n",
    "            print(f\"learning rate : {optimizer.param_groups[0]['lr']}\")\n",
    "        \n",
    "        progress.reset(task2)\n",
    "        progress.update(task1, advance=1)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print('Model saved to %s' % model_path)\n",
    "    # Print time\n",
    "    print(f\"Training finished: {int(time.time() - start_time_training)} seconds\")\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "## Add hyper parameters to tensorboard\n",
    "hyperparams = {\"CHR\": CHR, \"SNP\": SNP, \"ROLLUP LEVEL\": rollup_depth,\n",
    "               'PHENO_METHOD':pheno_method, 'EMBEDDING_METHOD':embedding_method,\n",
    "              'EMBEDDING SIZE': Embedding_size, 'ATTENTION HEADS': n_head, 'BLOCKS': n_layer,\n",
    "              'LR':1 , 'DROPOUT': p_dropout, 'NUM_EPOCHS': total_epochs, \n",
    "              'BATCH_SIZE': batch_size, \n",
    "              'PADDING_MASKING':masking_padding,\n",
    "              'VERSION': model_version,\n",
    "              'NB_Patients' : len(patient_list),\n",
    "              'LOSS_VERSION' : loss_version,\n",
    "\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from rich.progress import Progress\n",
    "\n",
    "with Progress() as progress:\n",
    "\n",
    "    task1 = progress.add_task(\"[red]Downloading...\", total=1000)\n",
    "    task2 = progress.add_task(\"[green]Processing...\", total=1000)\n",
    "    task3 = progress.add_task(\"[cyan]Cooking...\", total=1000)\n",
    "\n",
    "    while not progress.finished:\n",
    "        progress.update(task1, advance=0.5)\n",
    "        progress.update(task2, advance=0.3)\n",
    "        progress.update(task3, advance=0.9)\n",
    "        time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = [1,2,3]\n",
    "with Progress() as progress:\n",
    "    task1 = progress.add_task(\"[red]Downloading...\", total=3)\n",
    "    task2 = progress.add_task(\"blueDownloading...\", total=3)\n",
    "\n",
    "    for el in liste:\n",
    "        time.sleep(1)\n",
    "        for el in liste:\n",
    "            progress.update(task2, advance=1)\n",
    "            time.sleep(1)\n",
    "        progress.reset(task2)\n",
    "        progress.update(task1, advance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "with Progress() as progress:\n",
    "    task1 = progress.add_task(\"Training model\", total=total_epochs)\n",
    "    task2 = progress.add_task(\"epoch\", total=len(dataloader_train))\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        start_time_epoch = time.time()\n",
    "        total_loss = 0.0  \n",
    "\n",
    "        for batch_sentences, batch_counts, batch_labels in dataloader_train:\n",
    "\n",
    "            batch_sentences = batch_sentences.to(device)\n",
    "            batch_counts = batch_counts.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # evaluate the loss\n",
    "            logits, loss = model(batch_sentences, batch_counts, batch_labels)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "        \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            progress.update(task2, advance=1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        writer.add_scalar('Training loss', total_loss/len(dataloader_train), epoch)\n",
    "\n",
    "        if epoch % eval_interval == 0:\n",
    "            print(f\"Epoch {epoch} finished: {int(time.time() - start_time_epoch)} seconds\")\n",
    "            print(f\"    Training loss : {(total_loss/len(dataloader_train)):.4f}\")\n",
    "            f1, accuracy, report, auc_score, val_loss = model.evaluate(dataloader_test)\n",
    "            print(\" Evaluation on validation\")\n",
    "            print(f\"        Validation loss : {val_loss:.4f}\")\n",
    "            writer.add_scalar('Validation loss', val_loss, epoch)\n",
    "            writer.add_scalar('Validation AUC', auc_score, epoch)\n",
    "            writer.add_scalar('Validation f1-score', f1, epoch)\n",
    "            writer.add_scalar('Validation accuracy', accuracy, epoch)\n",
    "            \n",
    "            print(f\"learning rate : {optimizer.param_groups[0]['lr']}\")\n",
    "        \n",
    "        progress.reset(task2)\n",
    "        progress.update(task1, advance=1)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print('Model saved to %s' % model_path)\n",
    "    # Print time\n",
    "    print(f\"Training finished: {int(time.time() - start_time_training)} seconds\")\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randint(8, (2,2, 1))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.view(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/gpfs/commons/groups/gursoy_lab/mstoll/codes/models/list_models_class/list_instance_tests_saved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phewas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
