{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import statsmodels.api as sm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from codes.models.utils import number_tests\n",
    "from codes.models.data_form.DataForm import DataTransfo_1SNP\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from codes.models.metrics import calculate_roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### framework constants:\n",
    "model_type = 'decision_tree'\n",
    "model_version = 'gradient_boosting'\n",
    "test_name = '1_test_train_transfo_V1'\n",
    "option = 'pairwise'\n",
    "tryout = True # True if we are ding a tryout, False otherwise \n",
    "### data constants:\n",
    "### data constants:\n",
    "CHR = 6\n",
    "SNP = 'rs12203592'\n",
    "pheno_method = 'Paul' # Paul, Abby\n",
    "ld = 'no'\n",
    "rollup_depth = 4\n",
    "binary_classes = True #nb of classes related to an SNP (here 0 or 1)\n",
    "vocab_size = None # to be defined with data\n",
    "padding_token = 0\n",
    "prop_train_test = 0.8\n",
    "load_data = False\n",
    "save_data = True\n",
    "remove_none = True\n",
    "decorelate = False\n",
    "equalize_label = False\n",
    "threshold_corr = 0.9\n",
    "threshold_rare = 50\n",
    "remove_rare = 'all' # None, 'all', 'one_class'\n",
    "compute_features = True\n",
    "padding = False\n",
    "list_env_features = ['age', 'sex']\n",
    "list_pheno_ids = None #list(np.load(f'/gpfs/commons/groups/gursoy_lab/mstoll/codes/Data_Files/phewas/list_associations_snps/{SNP}_paul.npy'))\n",
    "\n",
    "### data format\n",
    "\n",
    "batch_size = 20\n",
    "data_share = 1\n",
    "\n",
    "##### model constants\n",
    "\n",
    "\n",
    "##### training constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/codes/'\n",
    "\n",
    "#check test name\n",
    "model_dir = path + f'logs/SNPS/{str(CHR)}/{SNP}/{model_type}/{model_version}/{pheno_method}'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "#check number tests\n",
    "number_test = number_tests(model_dir)\n",
    "test_name_with_infos = str(number_test) + '_' + test_name + 'tryout'*tryout\n",
    "test_dir = f'{model_dir}/{test_name_with_infos}/'\n",
    "log_data_dir = f'{test_dir}/data/'\n",
    "log_res_dir = f'{test_dir}/res/'\n",
    "log_slurm_outputs_dir = f'{test_dir}/Slurm/Outputs/'\n",
    "log_slurm_errors_dir = f'{test_dir}/Slurm/Errors/'\n",
    "\n",
    "os.makedirs(log_data_dir)\n",
    "os.makedirs(log_res_dir)\n",
    "os.makedirs(log_slurm_outputs_dir)\n",
    "os.makedirs(log_slurm_errors_dir)\n",
    "\n",
    "\n",
    "log_data_path_pickle = f'{test_dir}/data/{test_name}.pkl'\n",
    "\n",
    "\n",
    "log_res_path_pickle = f'{test_dir}/res/{test_name}_{option}.pkl'\n",
    "log_slurm_outputs_path = f'{test_dir}/Slurm/Outputs/{test_name}_{option}.pth'\n",
    "log_slurm_error_path = f'{test_dir}/Slurm/Errors/{test_name}_{option}.pth'\n",
    "\n",
    "   \n",
    "# Redirect  output to a file\n",
    "sys.stdout = open(log_slurm_outputs_path, 'w')\n",
    "sys.stderr = open(log_slurm_error_path, 'w')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = DataTransfo_1SNP(SNP=SNP,\n",
    "                         CHR=CHR,\n",
    "                         method=pheno_method,\n",
    "                         padding=padding,  \n",
    "                         pad_token=padding_token, \n",
    "                         load_data=load_data, \n",
    "                         save_data=save_data, \n",
    "                         compute_features=compute_features,\n",
    "                         prop_train_test=prop_train_test,\n",
    "                         remove_none=remove_none,\n",
    "                         equalize_label=equalize_label,\n",
    "                         rollup_depth=rollup_depth,\n",
    "                         decorelate=decorelate,\n",
    "                         threshold_corr=threshold_corr,\n",
    "                         threshold_rare=threshold_rare,\n",
    "                         remove_rare=remove_rare, \n",
    "                         list_env_features=list_env_features,\n",
    "                         data_share=data_share,\n",
    "                         list_pheno_ids=list_pheno_ids,\n",
    "                         binary_classes=binary_classes, \n",
    "                         ld = ld)\n",
    "#patient_list = dataT.get_patientlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels_patients, indices_env, name_envs, eids = dataT.get_tree_data(with_env=False, load_possible=True, only_relevant=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_ini = np.sum(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = True\n",
    "interest = False\n",
    "keep = True\n",
    "scaled = False\n",
    "remove = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interest:\n",
    "    data_use, labels_use = data[:nb_patients_interest, :-1], labels_patients[:nb_patients_interest]\n",
    "else:\n",
    "    data_use, labels_use = data, labels_patients\n",
    "if remove:\n",
    "    eids_remove = np.load('/gpfs/commons/groups/gursoy_lab/mstoll/codes/Data_Files/UKBB/eids_remove_1.npy')\n",
    "    indices_eids = (1-np.isin(eids, eids_remove)).astype(bool)\n",
    "    eids_use = eids[indices_eids]\n",
    "    data_use = data_use[indices_eids]\n",
    "    labels_use = labels_use[indices_eids]\n",
    "    \n",
    "if equalized:\n",
    "    pheno, labels = DataTransfo_1SNP.equalize_label(data=data_use, labels = labels_use)\n",
    "else:\n",
    "    pheno, labels = data_use, labels_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases_patients_train, diseases_patients_test, label_patients_train, label_patients_test = train_test_split(pheno, labels, test_size = 1-prop_train_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_keep = (frequencies_ini > 0) & (frequencies_ini > 1000)\n",
    "#indices_keep = shaps!=0\n",
    "diseases_patients_train_keep = diseases_patients_train[:,indices_keep]\n",
    "diseases_patients_test_keep = diseases_patients_test[:, indices_keep]\n",
    "if keep:\n",
    "    diseases_patients_train_model = diseases_patients_train_keep\n",
    "    diseases_patients_test_model = diseases_patients_test_keep\n",
    "else:\n",
    "    diseases_patients_train_model = diseases_patients_train\n",
    "    diseases_patients_test_model = diseases_patients_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(pheno_data, label_data, disp=False):\n",
    "    try:\n",
    "        logit_model = sm.Logit(label_data, pheno_data)\n",
    "        result = logit_model.fit(disp=disp)\n",
    "        p_value = result.pvalues[0]\n",
    "        coeff = result.params[0]\n",
    "        return p_value, coeff, result\n",
    "    except:\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_diseases = diseases_patients_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 10\n",
    "option = 'pairwise'\n",
    "pheno_data_train = diseases_patients_train_model\n",
    "label_data_train = label_patients_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_indexs = np.arange(nb_diseases)\n",
    "pheno_indexs_splits = np.array_split(pheno_indexs, nb_diseases // num_processes )\n",
    "\n",
    "## Open tensor board writer\n",
    "\"\"\"\n",
    "output_file = log_slurm_outputs_path\n",
    "with open(output_file, 'w') as file:\n",
    "    file.truncate()\n",
    "    file.close()\n",
    "\"\"\"\n",
    "start_time_cell = time.time()\n",
    "p_values = []\n",
    "coeffs = []\n",
    "models = []\n",
    "if option=='pairwise':\n",
    "    p_values = np.zeros(nb_diseases)\n",
    "    coeffs = np.zeros(nb_diseases)\n",
    "    label_data_train = [np.array(label_data_train) for _ in range(num_processes)]\n",
    "    for batch_phenos_index in tqdm(pheno_indexs_splits, desc=\"batch num\"):\n",
    "        start_time =  time.time()\n",
    "\n",
    "        if len(batch_phenos_index) == num_processes:\n",
    "            pool = Pool(processes=num_processes)\n",
    "            pheno_data_train_batch = [pheno_data_train[:, pheno_index] for pheno_index in batch_phenos_index]\n",
    "\n",
    "\n",
    "\n",
    "            results = pool.starmap(logreg, zip(pheno_data_train_batch, label_data_train))\n",
    "            # Fermez le pool de processus\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            p_values[batch_phenos_index]= np.array([result[0] for result in results])\n",
    "            coeffs[batch_phenos_index] = np.array([result[1] for result in results])\n",
    "            for result in results:\n",
    "                models.append(result[2])\n",
    "\n",
    "        else:\n",
    "            for pheno_index in batch_phenos_index:\n",
    "                pheno_data_train_batch = pheno_data_train[:, pheno_index]\n",
    "                p_value, coeff, model = logreg(pheno_data_train_batch, label_data_train)\n",
    "                p_values[pheno_index] = p_value\n",
    "                coeffs[pheno_index] = coeff\n",
    "                models.append(model)\n",
    "        print(f'batch finished in {time.time() - start_time} s')\n",
    "else:\n",
    "    p_value, coeff, model = logreg(pheno_data_train, label_data_train, disp=True)\n",
    "    models.append(model)\n",
    "    p_values.append(p_value)\n",
    "    coeffs.append(coeff)\n",
    "print(f'program over in {time.time()-start_time_cell}s')\n",
    "\n",
    "res_dic = {'option' : option,\n",
    "    'models' : models,\n",
    "    'p_values' : p_values,\n",
    "    'coeffs' : coeffs\n",
    "}\n",
    "\n",
    "#tree_data_dic = {'pheno_data_train' : pheno_data_train, 'pheno_data_test' : pheno_data_test, 'label_data_train' : label_data_train, 'label_data_test':label_data_test}\n",
    "\"\"\"\n",
    "with open(log_res_path_pickle, 'wb') as file:\n",
    "    pickle.dump(res_dic, file)\n",
    "print('Res saved to %s' % log_res_path_pickle)\n",
    "\n",
    "with open(log_data_path_pickle, 'wb') as file:\n",
    "    pickle.dump(tree_data_dic, file)\n",
    "print('Data saved to %s' % log_data_path_pickle)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_sample_weight(class_weight='balanced', y=label_patients_train)\n",
    "\n",
    "# Adjust the input data with the square root of weights\n",
    "sqrt_weights = np.sqrt(class_weights)\n",
    "pheno_data_train_weighted = diseases_patients_train * sqrt_weights[:, np.newaxis]\n",
    "column_one_train = np.ones((diseases_patients_train.shape[0],1 ))\n",
    "column_one_test = np.ones((diseases_patients_test.shape[0],1 ))\n",
    "\n",
    "pheno_data_train_weighted_with_constant=  np.concatenate([column_one_train, pheno_data_train_weighted], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_data_train_weighted = diseases_patients_train * sqrt_weights[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.Logit(label_patients_train, pheno_data_train_weighted_with_constant)\n",
    "result = logit_model.fit(method='bfgs', disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_data_train_with_constant =  np.concatenate([column_one_train, diseases_patients_train], axis = 1)\n",
    "pheno_data_test_with_constant =  np.concatenate([column_one_test, diseases_patients_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualisation des donnes avec df\n",
    "proba_test = result.predict(pheno_data_test_with_constant)\n",
    "proba_train = result.predict(pheno_data_train_weighted_with_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_test = (proba_test > 0.5).astype(int)\n",
    "nb_positive_test = np.sum(labels_pred_test==0)\n",
    "nb_negative_test = np.sum(labels_pred_test==1)\n",
    "labels_pred_train = (proba_train > 0.5).astype(int)\n",
    "nb_positive_train = np.sum(labels_pred_train==0)\n",
    "nb_negative_train = np.sum(labels_pred_train==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_test = np.sum((label_patients_test==0 )& (labels_pred_test == 0)) / nb_positive_test\n",
    "FP_test = np.sum((label_patients_test==1 )& (labels_pred_test == 0)) / nb_positive_test\n",
    "TN_test = np.sum((label_patients_test==1 )& (labels_pred_test == 1)) / nb_negative_test\n",
    "FN_test = np.sum((label_patients_test== 0)& (labels_pred_test == 1)) / nb_negative_test\n",
    "\n",
    "TP_train = np.sum((label_patients_train==0 )& (labels_pred_train == 0)) / nb_positive_train\n",
    "FP_train = np.sum((label_patients_train==1 )& (labels_pred_train == 0)) / nb_positive_train\n",
    "TN_train = np.sum((label_patients_train==1 )& (labels_pred_train == 1)) / nb_negative_train\n",
    "FN_train = np.sum((label_patients_train== 0)& (labels_pred_train == 1)) / nb_negative_train\n",
    "\n",
    "\n",
    "auc_test = calculate_roc_auc(label_patients_test, proba_test)\n",
    "auc_train = calculate_roc_auc(label_patients_train, proba_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_zeros = np.sum(label_patients_test==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels_pred_test==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{TP_test=}') \n",
    "print(f'{FP_test=}')\n",
    "print(f'{TN_test=}')\n",
    "print(f'{FN_test=}')\n",
    "print(f'{TP_train=}') \n",
    "print(f'{FP_train=}')\n",
    "print(f'{TN_train=}')\n",
    "print(f'{FN_train=}')\n",
    "\n",
    "print(f'{auc_test=}')\n",
    "print(f'{auc_train=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{TP_test=}') \n",
    "print(f'{FP_test=}')\n",
    "print(f'{TN_test=}')\n",
    "print(f'{FN_test=}')\n",
    "print(f'{TP_train=}') \n",
    "print(f'{FP_train=}')\n",
    "print(f'{TN_train=}')\n",
    "print(f'{FN_train=}')\n",
    "\n",
    "print(f'{auc_test=}')\n",
    "print(f'{auc_train=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(proba_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(proba_train[label_data_train==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phewas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
