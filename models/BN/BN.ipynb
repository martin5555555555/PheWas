{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import shap\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, classification_report\n",
    "from functools import partial\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from codes.models.data_form.DataForm import DataTransfo_1SNP\n",
    "from codes.models.metrics import calculate_roc_auc\n",
    "\n",
    "import featurewiz as gwiz\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from codes.models.Decision_tree.utils import get_indice, get_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pgmpy.estimators import PC, HillClimbSearch, ExhaustiveSearch\n",
    "from pgmpy.estimators import K2Score\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.sampling import BayesianModelSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data constants:\n",
    "CHR = 1\n",
    "SNP = 'rs673604'\n",
    "pheno_method = 'Abby' # Paul, Abby\n",
    "rollup_depth = 4\n",
    "Classes_nb = 2 #nb of classes related to an SNP (here 0 or 1)\n",
    "vocab_size = None # to be defined with data\n",
    "ld = 'no'\n",
    "padding_token = 0\n",
    "prop_train_test = 0.8\n",
    "load_data = True\n",
    "save_data = True\n",
    "remove_none = False\n",
    "decorelate = False\n",
    "equalize_label = False\n",
    "threshold_corr = 0.8\n",
    "threshold_rare = 1000\n",
    "remove_rare = 'all' # None, 'all', 'one_class'\n",
    "compute_features = True\n",
    "padding = True\n",
    "list_env_features = []\n",
    "list_phenos_ids = None#list(np.load('/gpfs/commons/groups/gursoy_lab/mstoll/codes/Data_Files/phewas/list_associations_snps/rs673604_paul.npy'))\n",
    "### data format\n",
    "batch_size = 20\n",
    "data_share = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = DataTransfo_1SNP(SNP=SNP,\n",
    "                         CHR=CHR,\n",
    "                         method=pheno_method,\n",
    "                         padding=padding,  \n",
    "                         pad_token=padding_token, \n",
    "                         load_data=load_data, \n",
    "                         save_data=save_data, \n",
    "                         compute_features=compute_features,\n",
    "                         prop_train_test=prop_train_test,\n",
    "                         remove_none=remove_none,\n",
    "                         equalize_label=equalize_label,\n",
    "                         rollup_depth=rollup_depth,\n",
    "                         decorelate=decorelate,\n",
    "                         threshold_corr=threshold_corr,\n",
    "                         threshold_rare=threshold_rare,\n",
    "                         remove_rare=remove_rare, \n",
    "                         list_env_features=list_env_features,\n",
    "                         data_share=data_share,\n",
    "                         list_pheno_ids=list_phenos_ids,\n",
    "                         ld=ld)\n",
    "#patient_list = dataT.get_patientlist()''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, indices_env, env_features, eids = dataT.get_tree_data(with_env=False, with_counts=False, load_possible=True, only_relevant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_keep_x, nb_phenos_keep = 100000, 100\n",
    "data_try = data[:nb_keep_x:, :nb_phenos_keep]\n",
    "columns = get_name(dataT, np.arange(nb_phenos_keep))\n",
    "df = pd.DataFrame(data = data_try, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PC algorithm object\n",
    "pc = PC(data=df)\n",
    "\n",
    "# Run the PC algorithm to learn the structure\n",
    "estimated_model = pc.estimate(variant='stable', max_cond_vars=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimated_model.edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_example_model('alarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to evaluate the learned model structures.\n",
    "def get_f1_score(estimated_model, true_model):\n",
    "    nodes = estimated_model.nodes()\n",
    "    est_adj = nx.to_numpy_array(\n",
    "        estimated_model.to_undirected(), nodelist=nodes, weight=None\n",
    "    )\n",
    "    true_adj = nx.to_numpy_array(\n",
    "        true_model.to_undirected(), nodelist=nodes, weight=None\n",
    "    )\n",
    "\n",
    "    f1 = f1_score(np.ravel(true_adj), np.ravel(est_adj))\n",
    "    print(\"F1-score for the model skeleton: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.where(r, 0.8, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd.Bernoulli(probs=tf.where(r, 0.8, 0.2)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phewas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
