{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import shap\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, classification_report\n",
    "from functools import partial\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from codes.models.data_form.DataForm import DataTransfo_1SNP\n",
    "from codes.models.metrics import calculate_roc_auc\n",
    "\n",
    "import featurewiz as gwiz\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from codes.models.Decision_tree.utils import get_indice, get_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### framework constants:\n",
    "model_type = 'decision_tree'\n",
    "model_version = 'gradient_boosting'\n",
    "test_name = '1_test_train_transfo_V1'\n",
    "pheno_method = 'Abby' # Paul, Abby\n",
    "tryout = True # True if we are ding a tryout, False otherwise \n",
    "### data constants:\n",
    "### data constants:\n",
    "CHR = 1\n",
    "SNP = 'rs673604'\n",
    "pheno_method = 'Paul' # Paul, Abby\n",
    "ld = 'no'\n",
    "rollup_depth = 4\n",
    "binary_classes = True #nb of classes related to an SNP (here 0 or 1)\n",
    "vocab_size = None # to be defined with data\n",
    "padding_token = 0\n",
    "prop_train_test = 0.8\n",
    "load_data = False\n",
    "save_data = True\n",
    "remove_none = True\n",
    "decorelate = False\n",
    "equalize_label = False\n",
    "threshold_corr = 0.9\n",
    "threshold_rare = 50\n",
    "remove_rare = 'all' # None, 'all', 'one_class'\n",
    "compute_features = True\n",
    "padding = False\n",
    "list_env_features = []\n",
    "list_pheno_ids = None #list(np.load(f'/gpfs/commons/groups/gursoy_lab/mstoll/codes/Data_Files/phewas/list_associations_snps/{SNP}_paul.npy'))\n",
    "\n",
    "### data format\n",
    "\n",
    "batch_size = 20\n",
    "data_share = 1\n",
    "\n",
    "##### model constants\n",
    "\n",
    "\n",
    "##### training constants\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = DataTransfo_1SNP(SNP=SNP,\n",
    "                         CHR=CHR,\n",
    "                         method=pheno_method,\n",
    "                         padding=padding,  \n",
    "                         pad_token=padding_token, \n",
    "                         load_data=load_data, \n",
    "                         save_data=save_data, \n",
    "                         compute_features=compute_features,\n",
    "                         prop_train_test=prop_train_test,\n",
    "                         remove_none=remove_none,\n",
    "                         equalize_label=equalize_label,\n",
    "                         rollup_depth=rollup_depth,\n",
    "                         decorelate=decorelate,\n",
    "                         threshold_corr=threshold_corr,\n",
    "                         threshold_rare=threshold_rare,\n",
    "                         remove_rare=remove_rare, \n",
    "                         list_env_features=list_env_features,\n",
    "                         data_share=data_share,\n",
    "                         list_pheno_ids=list_pheno_ids,\n",
    "                         binary_classes=binary_classes, \n",
    "                         ld = ld)\n",
    "#patient_list = dataT.get_patientlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels_patients, indices_env, name_envs, eids = dataT.get_tree_data(with_env=False, load_possible=True, only_relevant=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = True\n",
    "interest = False\n",
    "keep = True\n",
    "scaled = False\n",
    "remove = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_ini = np.sum(data, axis=0)\n",
    "print(f'imbalance : {np.sum(labels_patients==0)/len(labels_patients)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_keep = np.where(frequencies_ini > 2000)[0]\n",
    "#indices_keep = indices_shaps[:100]\n",
    "print(f'nb phenos kept : {indices_keep.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = get_name(dataT, indices_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if keep:\n",
    "    data_keep = data[:, indices_keep]\n",
    "    data_use, labels_use= data_keep[np.any(data_keep==1, axis=1)], labels_patients[np.any(data_keep==1, axis=1)]\n",
    "else:\n",
    "    data_use, labels_use = data, labels_patients\n",
    "\n",
    "if interest:\n",
    "    data_use, labels_use = data[:nb_patients_interest, :-1], labels_patients[:nb_patients_interest]\n",
    "else:\n",
    "    data_use, labels_use = data_use, labels_use\n",
    "if remove:\n",
    "    eids_remove = np.load('/gpfs/commons/groups/gursoy_lab/mstoll/codes/Data_Files/UKBB/eids_remove_1.npy')\n",
    "    indices_eids = (1-np.isin(eids, eids_remove)).astype(bool)\n",
    "    eids_use = eids[indices_eids]\n",
    "    data_use = data_use[indices_eids]\n",
    "    labels_use = labels_use[indices_eids]\n",
    "    \n",
    "if equalized:\n",
    "    pheno, labels = DataTransfo_1SNP.equalize_label(data = data_use, labels = labels_use)\n",
    "else:\n",
    "    pheno, labels = data_use, labels_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases_patients_train, diseases_patients_test, label_patients_train, label_patients_test = train_test_split(pheno, labels, test_size = 1-prop_train_test, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: np.sum(label_patients_train == 1) / np.sum(label_patients_train == 0), 1: 1.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "diseases_patients_train_model_unscaled = diseases_patients_train\n",
    "diseases_patients_test_model_unscaled = diseases_patients_test\n",
    "\n",
    "if scaled:\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    diseases_patients_train_model= scaler.fit_transform(diseases_patients_train)\n",
    "    diseases_patients_test_model = scaler.fit_transform(diseases_patients_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(diseases_patients_train_model, label_patients_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "labels_pred_test = (model.predict(diseases_patients_test_model) > 0.5).astype(int)\n",
    "labels_pred_train = (model.predict(diseases_patients_train_model) > 0.5).astype(int)\n",
    "proba_test = model.predict(diseases_patients_test_model)\n",
    "proba_train = model.predict(diseases_patients_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_positive_train = np.sum(labels_pred_train==0)\n",
    "nb_negative_train = np.sum(labels_pred_train==1)\n",
    "nb_positive_test = np.sum(labels_pred_test==0)\n",
    "nb_negative_test = np.sum(labels_pred_test==1)\n",
    "\n",
    "TP_test = np.sum((label_patients_test==0 )& (labels_pred_test == 0)) / nb_positive_test\n",
    "FP_test = np.sum((label_patients_test==1 )& (labels_pred_test == 0)) / nb_positive_test\n",
    "TN_test = np.sum((label_patients_test==1 )& (labels_pred_test == 1)) / nb_negative_test\n",
    "FN_test = np.sum((label_patients_test== 0)& (labels_pred_test == 1)) / nb_negative_test\n",
    "\n",
    "TP_train = np.sum((label_patients_train==0 )& (labels_pred_train == 0)) / nb_positive_train\n",
    "FP_train = np.sum((label_patients_train==1 )& (labels_pred_train == 0)) / nb_positive_train\n",
    "TN_train = np.sum((label_patients_train==1 )& (labels_pred_train == 1)) / nb_negative_train\n",
    "FN_train = np.sum((label_patients_train== 0)& (labels_pred_train == 1)) / nb_negative_train\n",
    "\n",
    "accuracy_train = accuracy_score(label_patients_train, labels_pred_train)\n",
    "accuracy_test = accuracy_score(label_patients_test, labels_pred_test)\n",
    "\n",
    "auc_test = calculate_roc_auc(label_patients_test, proba_test)\n",
    "auc_train = calculate_roc_auc(label_patients_train, proba_train)\n",
    "\n",
    "proba_avg_zero_test = 1- np.mean(proba_test[label_patients_test==0])\n",
    "proba_avg_zero_train = 1- np.mean(proba_train[label_patients_train==0])\n",
    "proba_avg_one_test = np.mean(proba_test[label_patients_test==1])\n",
    "proba_avg_one_train = np.mean(proba_train[label_patients_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{TP_test=}') \n",
    "print(f'{FP_test=}')\n",
    "print(f'{TN_test=}')\n",
    "print(f'{FN_test=}')\n",
    "print(f'{TP_train=}') \n",
    "print(f'{FP_train=}')\n",
    "print(f'{TN_train=}')\n",
    "print(f'{FN_train=}')\n",
    "print(' ')\n",
    "print(f'{auc_test=}')\n",
    "print(f'{auc_train=}')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(f'{accuracy_test=}')\n",
    "print(f'{accuracy_train=}')\n",
    "print(' ')\n",
    "print(f'{proba_avg_zero_test=}')\n",
    "print(f'{proba_avg_zero_train=}')\n",
    "print(f'{proba_avg_one_test=}')\n",
    "print(f'{proba_avg_one_train=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(coeffs, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(coeffs)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_name(dataT, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = get_indice(dataT, 'Actinic keratosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = 0\n",
    "x = data[:, indice]\n",
    "\n",
    "def get_F_pheno(data, labels, pheno_nb):    \n",
    "    labels_1 = labels[data[:,pheno_nb]==1]\n",
    "    labels_0 = labels[data[:,pheno_nb]==0]\n",
    "    P0 = np.sum(labels_0==1)/len(labels_0)\n",
    "    P1 = np.sum(labels_1==1)/len(labels_1)\n",
    "    F0 = max(P0, 1-P0)\n",
    "    F1 = max(P1, 1-P1)\n",
    "    return P0, P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(x, labels_patients)[0,1]\n",
    "P0, P1 = get_F_pheno(data, labels_patients, indice)\n",
    "diff_p = np.abs(P0 - P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_p, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.binomial(1, 0.5, 1000)\n",
    "Y = np.random.binomial(1, 0.5, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "coorx = np.corrcoef(X, Y)[0,1] \n",
    "P0x = np.sum(Y[X==0]==1)/np.sum(X==0)\n",
    "P1x = np.sum(Y[X==1]==1)/np.sum(X==1)\n",
    "diff_px = P0x - P1x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "coorx, diff_px, P0x, P1x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_pheno(data, labels, pheno_nb):    \n",
    "    corr = np.corrcoef(data[:, pheno_nb], labels)[0,1]\n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(np.abs(corrs))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_name(dataT, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keep = data[:, indices_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F_pheno(data, labels, pheno_nb):    \n",
    "    labels_1 = labels[data[:,pheno_nb]==1]\n",
    "    labels_0 = labels[data[:,pheno_nb]==0]\n",
    "    P0 = np.sum(labels_0==1)/len(labels_0)\n",
    "    P1 = np.sum(labels_1==1)/len(labels_1)\n",
    "    F0 = max(P0, 1-P0)\n",
    "    F1 = max(P1, 1-P1)\n",
    "    return P0, P1\n",
    "def get_plots_F(data, labels):\n",
    "    \n",
    "    get_risk_pheno = partial(get_F_pheno, data, labels)\n",
    "    frequencies = np.sum(data, axis=0) / len(data)\n",
    "    seuil_frequencies = -1\n",
    "    indices = frequencies*len(data) > seuil_frequencies\n",
    "    print(indices.sum())\n",
    "    proba_mean = max(np.sum(labels==0)/len(labels), 1-np.sum(labels==0)/len(labels))\n",
    "    phenos = np.arange(len(data[0]))[indices]\n",
    "    Fs = np.array(list(map(get_risk_pheno, phenos)))\n",
    "\n",
    "    plt.plot(Fs[:,0], 'o')\n",
    "    plt.plot(Fs[:, 1], 'o')\n",
    "    plt.xlabel('phenotypes')\n",
    "    plt.ylabel('probas label 1')\n",
    "    plt.axhline(proba_mean)\n",
    "    log_freq = np.log(frequencies*len(data)+1)[indices]\n",
    "    color_values = log_freq\n",
    "\n",
    "    diff_p = np.abs(Fs[:,0]-Fs[:,1]) *100\n",
    "    plt.legend(['P0', 'P1'])\n",
    "\n",
    "    fig = plt.subplots(figsize=(10, 10))\n",
    "    plt.scatter(np.arange(len(diff_p)), diff_p, c=color_values, cmap='viridis')\n",
    "    plt.xlabel('phenos')\n",
    "    plt.ylabel('diff_p')\n",
    "    plt.colorbar()\n",
    "    return Fs\n",
    "Fs = get_plots_F(data_keep, labels_patients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_pheno = partial(get_corr_pheno, data_keep, labels_patients)\n",
    "phenos = np.arange(len(data_keep[0]))\n",
    "corrs = np.array(list(map(get_corr_pheno, phenos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_p = np.abs(Fs[:,0]-Fs[:,1]) *100\n",
    "PX = np.sum(data_keep, axis=0)/len(data_keep)\n",
    "corrp = diff_p * np.sqrt(PX)\n",
    "indices_fs = np.argsort(diff_p)[::-1]\n",
    "indices_corrp = np.argsort(corrp)[::-1]\n",
    "indices_corrs = np.argsort(np.abs(corrs))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.argsort(corrp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(corrp[u], np.abs(corrs)[u], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(diff_p[indices_fs], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[indices_fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = get_indice(dataT, 'Actinic keratosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_p[indice], frequencies_ini[indice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_name(dataT, indices_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_name(dataT, indices_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_name(dataT, indices_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X =np.random.binomial(1, 0.5, size=N)\n",
    "Y =np.random.binomial(1, 0.5, size=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(X, Y)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrc = np.sum(X & Y)/N - np.sum(X)*np.sum(Y)/N/N\n",
    "P1 = np.sum(Y[X==1]) / np.sum(X==1)\n",
    "P0 = np.sum(Y[X==0]) / np.sum(X==0)\n",
    "PX = np.sum(X)/N\n",
    "diff_p = P1 - P0\n",
    "corr = np.corrcoef(X, Y)[0,1]\n",
    "manual = PX * (1 - PX) * (P1 - P0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrc, corr, diff_p, manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "P0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1, P0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diseases_patients_train[:,132]\n",
    "Y = labels_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = np.sum(Y[X==1]) / np.sum(X==1)\n",
    "P0 = np.sum(Y[X==0]) / np.sum(X==0)\n",
    "diff_p = P1 - P0\n",
    "corr = np.corrcoef(X, Y)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_p, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_indice(dataT, 'Cerebrovascular accident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phewas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
