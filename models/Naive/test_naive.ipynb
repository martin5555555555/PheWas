{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/gpfs/commons/groups/gursoy_lab/mstoll/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "from codes.models.data_form.DataForm import DataTransfo_1SNP, PatientList\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    labels_1 = labels[data[:,pheno_nb]==1]\n",
    "    labels_0 = labels[data[:,pheno_nb]==0]\n",
    "    P0 = np.sum(labels_0==1)/len(labels_0)\n",
    "    P1 = np.sum(labels_1==1)/len(labels_1)\n",
    "    F0 = max(P0, 1-P0)\n",
    "    F1 = max(P1, 1-P1)\n",
    "    return F0, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data constants:\n",
    "CHR = 1\n",
    "SNP = 'rs673604'\n",
    "pheno_method = 'Abby' # Paul, Abby\n",
    "rollup_depth = 4\n",
    "Classes_nb = 2 #nb of classes related to an SNP (here 0 or 1)\n",
    "vocab_size = None # to be defined with data\n",
    "padding_token = 0\n",
    "prop_train_test = 0.8\n",
    "load_data = False\n",
    "save_data = False\n",
    "remove_none = True\n",
    "decorelate = True\n",
    "equalize_label = False\n",
    "threshold_corr = 0.9\n",
    "threshold_rare = 50\n",
    "remove_rare = 'all' # None, 'all', 'one_class'\n",
    "compute_features = True\n",
    "padding = False\n",
    "list_env_features = ['age', 'sex']\n",
    "### data format\n",
    "batch_size = 20\n",
    "data_share = 1/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = DataTransfo_1SNP(SNP=SNP,\n",
    "                         CHR=CHR,\n",
    "                         method=pheno_method,\n",
    "                         padding=padding,  \n",
    "                         pad_token=padding_token, \n",
    "                         load_data=load_data, \n",
    "                         save_data=save_data, \n",
    "                         compute_features=compute_features,\n",
    "                         prop_train_test=prop_train_test,\n",
    "                         remove_none=True,\n",
    "                         equalize_label=equalize_label,\n",
    "                         rollup_depth=rollup_depth,\n",
    "                         decorelate=decorelate,\n",
    "                         threshold_corr=threshold_corr,\n",
    "                         threshold_rare=threshold_rare,\n",
    "                         remove_rare=remove_rare, \n",
    "                         list_env_features=list_env_features,\n",
    "                         data_share=data_share)\n",
    "#patient_list = dataT.get_patientlist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, indices_env, name_envs = dataT.get_tree_data(with_env=False)\n",
    "data, labels = DataTransfo_1SNP.equalize_label(data, labels)\n",
    "nb_phenos = data.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### decorelate the dataTree\n",
    "np.sum(data.var(axis=0)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos = np.arange(nb_phenos)\n",
    "\n",
    "def get_risk_pheno(data, labels, pheno_nb):\n",
    "    labels_ac = labels[data[:,pheno_nb]==1]\n",
    "    labels_deac = labels[data[:,pheno_nb]==0]\n",
    "    proba_mut_ac = np.sum(labels_ac==1)/len(labels_ac)\n",
    "    proba_mut_deac = np.sum(labels_deac==1)/len(labels_deac)\n",
    "    ratio  = proba_mut_ac / proba_mut_deac\n",
    "    return ratio\n",
    "def get_pred_naive(data, labels, pheno_nb, proba=False):\n",
    "    labels_ac = labels[data[:,pheno_nb]==1]\n",
    "    nb_ones_ac = np.sum(labels_ac==1)\n",
    "    nb_zeros_ac = np.sum(labels_ac==0)\n",
    "    proba = nb_zeros_ac / len(labels_ac)\n",
    "    label = (1 if nb_ones_ac > nb_zeros_ac else 0)\n",
    "    return proba, label\n",
    "get_risk_pheno = partial(get_risk_pheno, data, labels)\n",
    "get_pred_naive = partial(get_pred_naive, data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_ratios = list(map(get_risk_pheno, phenos))\n",
    "pred_naive = np.array(list(map(get_pred_naive, phenos)))\n",
    "probas_pred_naive = pred_naive[:, 0]\n",
    "labels_pred_naive = pred_naive[:, 1]\n",
    "\n",
    "def get_pred_sentence(probas_pred_naive, labels_pred_naive, sentence, method='max'):\n",
    "    sentence = sentence.astype(bool)\n",
    "    labels_naive = labels_pred_naive[sentence].astype(bool)\n",
    "    probas_naive = probas_pred_naive[sentence].astype(bool)\n",
    "\n",
    "    if method=='mean':\n",
    "        if np.mean(probas_naive)>0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    if method=='max':\n",
    "        argmax = np.argmax((probas_naive-0.5)**2)\n",
    "        return labels_naive[argmax]\n",
    "    \n",
    "#get_pred_sentence = partial(get_pred_sentence, probas_pred_naive, labels_pred_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = 1 - np.isnan(probas_pred_naive)\n",
    "data = data[:, mask]\n",
    "probas_pred_naive = probas_pred_naive[mask]\n",
    "labels_pred_naive = labels_pred_naive[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred_sentence = partial(get_pred_sentence, probas_pred_naive, labels_pred_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = np.sum(data, axis=0)\n",
    "labels_pred  = np.apply_along_axis(get_pred_sentence, arr=data, axis=1)\n",
    "np.sum(labels_pred == labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(probas_pred_naive[np.sqrt((probas_pred_naive-0.5)**2)>0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(frequencies[np.sqrt((probas_pred_naive-0.5)**2)>0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(probas_pred_naive==0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_pred_naive.notnan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies[np.argwhere(np.isnan(probas_pred_naive))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phewas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
